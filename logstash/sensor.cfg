input {
  # Input listen on TCP port 50000, using the json codec
  udp {
    id => "udp_input"
    port => 50000
    codec => json
  }
  jdbc {
    id => "jdbc_input"
    jdbc_driver_library => "../../logstash/sqlite-jdbc-3.30.1.jar"
    jdbc_driver_class => ""
    jdbc_user => ""
    jdbc_connection_string => "jdbc:sqlite:../../sqlite/sensor.db"
    parameters => { "sensor_id" => 1 }
    schedule => "*/1 * * * *"
    statement => "SELECT * from sensor as s JOIN measurement as m on s.id = m.sensor_id where s.id = :sensor_id"
  }
}

filter {
  mutate {
    id => "mutate_filter"
    # copy only important fields
    copy => {
      "[name]" => "sensor_name"
      "[timestamp]" => "sensor_timestamp"
      "[value]" => "sensor_value"
    }
    copy => {
      "[sensor][sensor_id]" => "sensor_id"
      "[sensor][sensor_name]" => "sensor_name"
      "[sensor][sensor_value]" => "sensor_value"
      "[sensor][sensor_timestamp]" => "sensor_timestamp"
    }
    # remove unused fields
    remove_field => ["name", "timestamp", "value", "id", "logger_name", "level", "host", "stack_info", "type", "sensor", "path", "tags"]
  }
  date {
    id => "date_filter"
    match => [ "sensor_timestamp", "ISO8601" ]
    target => "sensor_timestamp"
  }
}

output {
  if [sensor_id] == 0 {
    # Output to Kafka
    kafka {
      id => "kafka_output"
      codec => json
      topic_id => "sensors"
      message_key => "%{message}"
      bootstrap_servers => "http://localhost:9092"
    }
  }
  if [sensor_id] == 1 {
    # Output to Elasticsearch
    elasticsearch {
      id => "elasticsearch_output"
      hosts => ["localhost:9200"]
      document_id => "%{sensor_name}_%{sensor_timestamp}"
      index => "sensor"
    }
  }

  # Output to stdout
  stdout {
    id => "stdout_output"
  }
}